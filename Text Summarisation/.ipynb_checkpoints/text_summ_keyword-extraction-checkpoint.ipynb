{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4268995f6cee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummarization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummarizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummarization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mspellchecker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpellChecker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwordnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordNetError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "from gensim.summarization.summarizer import summarize \n",
    "from gensim.summarization import keywords \n",
    "from spellchecker import SpellChecker \n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus.reader.wordnet import WordNetError\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "def get_word_synonyms_from_sent(word, sent):\n",
    "    word_synonyms = []\n",
    "    for synset in wordnet.synsets(word):\n",
    "        for lemma in synset.lemma_names():\n",
    "            if lemma in sent and lemma != word:\n",
    "                word_synonyms.append(lemma)\n",
    "    return word_synonyms\n",
    "\n",
    "def get(word, sent):\n",
    "    word_synonyms = []\n",
    "    for synset in wordnet.synsets(word):\n",
    "        for lemma in synset.lemma_names():\n",
    "            word_synonyms.append(lemma)\n",
    "    return word_synonyms\n",
    "            \n",
    "\n",
    "with open('wikicontent.txt', 'r') as file:\n",
    "    data = file.read().replace('\\n', '')\n",
    "    \n",
    "print(\"Original text\"+\"\\n\")\n",
    "print(data)\n",
    "print(\"\\n\")\n",
    "m2=data\n",
    "spell = SpellChecker() \n",
    "data=data.replace('vv','w')\n",
    "data=data.replace('uu','w')\n",
    "# find those words that may be misspelled \n",
    "\n",
    "word = data.split(' ')\n",
    "z=[]\n",
    "for x in word:\n",
    "    z.append(spell.correction(x))\n",
    "\n",
    "m=' '\n",
    "data=m.join(z)\n",
    "print('data:-'+'\\n'+data)\n",
    "summ_per = summarize(m2, ratio = 0.2) \n",
    "print(\"Percent summary\"+\"\\n\") \n",
    "print(summ_per) \n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Keywords:-\"+\"\\n\")\n",
    "a=keywords(data).split('\\n') \n",
    "for i in summ_per.split(' '):\n",
    "    a.append(i)\n",
    "    \n",
    "w = ['communicable','lung','antibiotics','bacteria','Mycobacterium','6 months']\n",
    "count=0\n",
    "print(a)\n",
    "for word in w:\n",
    "    if word in a:\n",
    "        print (\"MATCH FOR '\" + word.upper() + \"' FOUND IN THE SENTENCE\" )\n",
    "        count=count+1\n",
    "    else:\n",
    "        word_synonyms = get_word_synonyms_from_sent(word, a)\n",
    "        if word_synonyms:\n",
    "            print (\"SYNONYMS FOR '\" + word.upper() + \"' FOUND IN THE SENTENCE: \" + \", \".join(word_synonyms))\n",
    "            count=count+1\n",
    "        else:\n",
    "            print (\"NO MATCH FOUND FOR '\" + word.upper() + \"' FOUND IN THE SENTENCE\" )\n",
    "\n",
    "score=count/len(w)\n",
    "score=score*5\n",
    "if (score-round(score))>0.5:\n",
    "    score=round(score)+1\n",
    "elif (score-round(score))>0.25:\n",
    "    score=round(score)+0.5\n",
    "else:\n",
    "    score=round(score)\n",
    "print('Marks awarded : {}/{}'.format(score,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
